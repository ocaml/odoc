<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml"><head><title>Parser (csexp.csexp.Csexp.Make.Parser)</title><meta charset="utf-8"/><link rel="stylesheet" href="../../../../../odoc.css"/><meta name="generator" content="odoc %%VERSION%%"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><script src="../../../../../highlight.pack.js"></script><script>hljs.initHighlightingOnLoad();</script><script>let base_url = '../../../../../';
let search_urls = ['../../../../sherlodoc_db.js','../../../../../sherlodoc.js'];
</script><script src="../../../../../odoc_search.js" defer="defer"></script></head><body class="odoc"><nav class="odoc-nav"><a href="../index.html">Up</a> ‚Äì <a href="../../../../../index.html">üè†</a> &#x00BB; <a href="../../../../index.html">csexp</a> &#x00BB; Library <code>csexp</code> &#x00BB; <a href="../../index.html">Csexp</a> &#x00BB; <a href="../index.html">Make</a> &#x00BB; Parser</nav><div class="odoc-search"><div class="search-inner"><input class="search-bar" placeholder="üîé Type '/' to search..."/><div class="search-snake"></div><div class="search-result"></div></div></div><header class="odoc-preamble"><h1>Module <code><span>Make.Parser</span></code><a href="../../../../src/csexp/csexp.ml.html#module-Make.module-Parser" class="source_link">Source</a></h1><p>The <code>Parser</code> module offers an API that is a balance between sharing the common logic of parsing canonical S-expressions while allowing to write parsers that are as efficient as possible, both in terms of speed and allocations. A carefully written parser using this API will be:</p><ul><li>fast</li><li>perform minimal allocations</li><li>perform zero <code>caml_modify</code> (a slow function of the OCaml runtime that is emitted when mutating a constructed value)</li></ul></header><div class="odoc-tocs"><nav class="odoc-toc odoc-local-toc"><ul><li><a href="#lexers">Lexers</a></li><li><a href="#parsing-stacks">Parsing stacks</a></li><li><a href="#parsing-errors">Parsing errors</a></li><li><a href="#building-a-parsing-function">Building a parsing function</a></li></ul></nav><nav class="odoc-toc odoc-global-toc"><ul><li><a href="../../../../index.html">csexp</a><ul><li>Library <code>csexp</code><ul><li><a href="../../index.html">Csexp</a><ul><li><a href="../../module-type-Sexp/index.html">Sexp</a></li><li><a href="../../module-type-S/index.html">S</a></li><li><a href="../index.html">Make</a><ul><li><a href="#" class="current_unit">Parser</a><ul><li><a href="Lexer/index.html">Lexer</a></li><li><a href="Stack/index.html">Stack</a></li></ul></li><li><a href="../module-type-Input/index.html">Input</a></li><li><a href="../Make_parser/index.html">Make_parser</a></li></ul></li><li><a href="../../Parser/index.html">Parser</a></li><li><a href="../../module-type-Input/index.html">Input</a></li><li><a href="../../Make_parser/index.html">Make_parser</a></li></ul></li></ul></li><li><a href="../../../../src/index.html">Sources</a></li></ul></li></ul></nav></div><div class="odoc-content"><h3 id="lexers"><a href="#lexers" class="anchor"></a>Lexers</h3><p>To parse using this API, you must first create a lexer via <a href="Lexer/index.html#val-create"><code>Lexer.create</code></a>. The lexer is responsible for scanning the input and forming tokens. The user must feed characters read from the input one by one to the lexer until it yields a token. For instance:</p><pre class="language-ocaml"><code># let lexer = Lexer.create ();;
val lexer : Lexer.t = &lt;abstract&gt;
# Lexer.feed lexer '(';;
- : [ `atom | `other ] Lexer.token = Lparen
# Lexer.feed lexer ')';;
- : [ `atom | `other ] Lexer.token = Rparen</code></pre><p>When the lexer doesn't have enough to return a token, it simply returns the special token <a href="Lexer/index.html#type-token.Await"><code>Lexer.token.Await</code></a>:</p><pre class="language-ocaml"><code># Lexer.feed lexer '1';;
- : [ `atom | `other ] Lexer.token = Await</code></pre><p>Note that since atoms of canonical S-expressions do not need quoting, they are always represented as a contiguous sequence of characters that don't need further processing. To achieve maximum efficiency, the lexer only returns the length of the atom and it is the responsibility of the caller to extract the atom from the input source:</p><pre class="language-ocaml"><code># Lexer.feed lexer '2';;
- : [ `atom | `other ] Lexer.token = Await
# Lexer.feed lexer ':';;
- : [ `atom | `other ] Lexer.token = Atom 2</code></pre><p>When getting <code>Atom n</code>, the caller should then proceed to read the next <code>n</code> characters of the input as a string. For instance, if the input is an <code>in_channel</code> the caller should proceed with <code>really_input_string ic n</code>.</p><p>Finally, when the end of input is reached the user should call <a href="Lexer/index.html#val-feed_eoi"><code>Lexer.feed_eoi</code></a> to make sure the lexer is not awaiting more input. If that is the case, <a href="Lexer/index.html#val-feed_eoi"><code>Lexer.feed_eoi</code></a> will raise:</p><pre class="language-ocaml"><code># Lexer.feed lexer '1';;
- : [ `atom | `other ] Lexer.token = Await
# Lexer.feed_eoi lexer;;
Exception: Parse_error &quot;premature end of input&quot;.</code></pre><h3 id="parsing-stacks"><a href="#parsing-stacks" class="anchor"></a>Parsing stacks</h3><p>The lexer doesn't keep track of the structure of the S-expressions. In order to construct a whole structured S-expressions, the caller must maintain a parsing stack via the <a href="Stack/index.html"><code>Stack</code></a> module. A <a href="Stack/index.html#type-t"><code>Stack.t</code></a> value simply represent a parsed prefix in reverse order.</p><p>For instance, the prefix &quot;1:x((1:y1:z)&quot; will be represented as:</p><pre class="language-ocaml"><code>Sexp (List [ Atom &quot;y&quot;; Atom &quot;z&quot; ], Open (Sexp (Atom &quot;x&quot;, Empty)))</code></pre><p>The <a href="Stack/index.html"><code>Stack</code></a> module offers various primitives to open or close parentheses or insert an atom. And for convenience it provides a function <a href="Stack/index.html#val-add_token"><code>Stack.add_token</code></a> that takes the output of <a href="Lexer/index.html#val-feed"><code>Lexer.feed</code></a> directly:</p><pre class="language-ocaml"><code># Stack.add_token Rparen Empty;;
- : Stack.t = Open Empty
# Stack.add_token Lparen (Open Empty);;
- : Stack.t = Sexp (List [], Empty)</code></pre><p>Note that <a href="Stack/index.html#val-add_token"><code>Stack.add_token</code></a> doesn't accept <code>Atom _</code>. This is enforced at the type level by a GADT. The reason for this is that in order to insert an atom, the user must have fetched the contents of the atom themselves. In order to insert an atom into a stack, you can use the function <a href="Stack/index.html#val-add_atom"><code>Stack.add_atom</code></a>:</p><pre class="language-ocaml"><code># Stack.add_atom &quot;foo&quot; (Open Empty);;
- : Stack.t = Sexp (Atom &quot;foo&quot;, Open Empty)</code></pre><p>When parsing is finished, one may call the function <a href="Stack/index.html#val-to_list"><code>Stack.to_list</code></a> in order to extract all the toplevel S-expressions from the stack:</p><pre class="language-ocaml"><code># Stack.to_list (Sexp (Atom &quot;x&quot;, Sexp (List [Atom &quot;y&quot;], Empty)));;
- : sexp list = [List [Atom &quot;y&quot;; Atom &quot;x&quot;]]</code></pre><p>If instead you want to stop parsing as soon a single full S-expression has been discovered, you can match on the structure of the stack. If the stack is of the form <code>Sexp (_, Empty)</code>, then you know that exactly one S-expression has been parsed and you can stop there.</p><h3 id="parsing-errors"><a href="#parsing-errors" class="anchor"></a>Parsing errors</h3><p>In order to reduce allocations to a minumim, parsing errors are reported via the exception <a href="#exception-Parse_error"><code>Parse_error</code></a>. It is the responsibility of the caller to catch this exception and return it as an <code>Error _</code> value. Functions that may raise <code>Parse_error</code> are documented as such.</p><p>When extracting an atom and the input doesn't have enough characters left, the user may raise <code>Parse_error premature_end_of_input</code>. This will produce an error message similar to what the various high-level functions of this library produce.</p><h3 id="building-a-parsing-function"><a href="#building-a-parsing-function" class="anchor"></a>Building a parsing function</h3><p>Parsing functions should always follow the following pattern:</p><ol><li>create a lexer and start with an empty parsing stack</li><li>iterate over the input, feeding the lexer characters one by one. When the lexer returns <code>Atom n</code>, fetch the next <code>n</code> characters from the input to form an atom</li><li>update the stack via <code>Stack.add_atom</code> or <code>Stack.add_token</code></li><li>if parsing the whole input, call <code>Lexer.feed_eoi</code> when the end of input is reached, otherwise stop as soon as the stack is of the form <code>Sexp (_, Empty)</code> -</li></ol><p>For instance, to parse a string as a list of S-expressions:</p><pre class="language-ocaml"><code>module Sexp = struct
  type t =
    | Atom of string
    | List of t list
end

module Csexp = Csexp.Make (Sexp)

let extract_atom s pos len =
  match String.sub s pos len with
  | exception _ -&gt;
    (* Turn out-of-bounds errors into [Parse_error] *)
    raise (Parse_error premature_end_of_input)
  | s -&gt; s

let parse_string =
  let open Csexp.Parser in
  let rec loop s pos len lexer stack =
    if pos = len then (
      Lexer.feed_eoi lexer;
      Stack.to_list stack)
    else
      match Lexer.feed lexer (String.unsafe_get s pos) with
      | Atom atom_len -&gt;
        let atom = extract_atom s (pos + 1) atom_len in
        loop s (pos + 1 + atom) len lexer (Stack.add_atom atom stack)
      | (Await | Lparen | Rparen) as x -&gt;
        loop s (pos + 1) len lexer (Stack.add_token x stack)
  in
  fun s -&gt;
    match loop s 0 (String.length s) (Lexer.create ()) Empty with
    | v -&gt; Ok v
    | exception Parse_error msg -&gt; Error msg</code></pre><div class="odoc-spec"><div class="spec exception anchored" id="exception-Parse_error"><a href="#exception-Parse_error" class="anchor"></a><a href="../../../../src/csexp/csexp.ml.html#module-Make.module-Parser.exception-Parse_error" class="source_link">Source</a><code><span><span class="keyword">exception</span> </span><span><span class="exception">Parse_error</span> <span class="keyword">of</span> string</span></code></div></div><div class="odoc-spec"><div class="spec value anchored" id="val-premature_end_of_input"><a href="#val-premature_end_of_input" class="anchor"></a><a href="../../../../src/csexp/csexp.ml.html#module-Make.module-Parser.val-premature_end_of_input" class="source_link">Source</a><code><span><span class="keyword">val</span> premature_end_of_input : string</span></code></div><div class="spec-doc"><p>Error message signaling the end of input was reached prematurely. You can use this when extracting an atom from the input and the input doesn't have enough characters.</p></div></div><div class="odoc-spec"><div class="spec module anchored" id="module-Lexer"><a href="#module-Lexer" class="anchor"></a><a href="../../../../src/csexp/csexp.ml.html#module-Make.module-Parser.module-Lexer" class="source_link">Source</a><code><span><span class="keyword">module</span> <a href="Lexer/index.html">Lexer</a></span><span> : <span class="keyword">sig</span> ... <span class="keyword">end</span></span></code></div><div class="spec-doc"><p>Lexical analyser</p></div></div><div class="odoc-spec"><div class="spec module anchored" id="module-Stack"><a href="#module-Stack" class="anchor"></a><a href="../../../../src/csexp/csexp.ml.html#module-Make.module-Parser.module-Stack" class="source_link">Source</a><code><span><span class="keyword">module</span> <a href="Stack/index.html">Stack</a></span><span> : <span class="keyword">sig</span> ... <span class="keyword">end</span></span></code></div><div class="spec-doc"><p>Parsing stack</p></div></div></div></body></html>
